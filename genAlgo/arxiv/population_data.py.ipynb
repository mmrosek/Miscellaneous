{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dna_data' from '/home/mjmrose/workspace/sbox-mjmrose/Bids/genAlgo/dna_data.py'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dna_data\n",
    "from dna_data import DNA # To get this to work, needed to put 'if name == main' at bottom of dna.py \n",
    "importlib.reload(dna_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to describe a population of virtual organisms\n",
    "# In this case, each organism is just an instance of a DNA object\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, data, preproc_algos, models, tgt, mut_rate, pop_sz, fit_exp, eval_perc, mating_pool_retain_perc, replace=True, midpt=False, verbose=False, debug=False):\n",
    "\n",
    "        self.population = [] \n",
    "        self.mating_pool = [] \n",
    "        self.generations = 0\n",
    "        self.finished = False \n",
    "        self.mut_rate = mut_rate\n",
    "        self.perfect_score = 0.2\n",
    "        self.best = \"\"\n",
    "        self.fitness_sum = 0\n",
    "        self.fit_exp = fit_exp # Raise fitness to this power to increase (if > 1) prob. of higher fitness members breeding\n",
    "        self.eval_perc = eval_perc/100 # % of members of population to evaluate and replace for 2nd+ generation\n",
    "        self.mating_pool_retain_perc = mating_pool_retain_perc/100 # % of top fitness mems in mating pool to NOT replace\n",
    "        self.replace_bool = replace # True: replace 'num_new_mems' mems of pop w/ lowest fitness w/ new children // False: new children will be appended to existing population\n",
    "        self.verbose = verbose\n",
    "        self.debug = debug\n",
    "        self.eval_idxs = []\n",
    "        \n",
    "        # If not all mems of pop are being evaluated in each generation, can't use fitness for breeding\n",
    "        if self.eval_perc != 1: self.midpt_bool = False # True: Choose point to split mems being bred // False: probabilistically select gene from one of mems being bred based on fitness\n",
    "        else: self.midpt_bool = False\n",
    "            \n",
    "        # NEW - 10/10\n",
    "        if len(preproc_algos) != len(data): self.preproc_algos = []\n",
    "        else: self.preproc_algos = preproc_algos\n",
    "            \n",
    "        # Creating dictionary of dataframes to avoid passing actual df to each DNA instance\n",
    "        self.data_dict = {}\n",
    "        if (type(data) == list) & (len(data) > 0):\n",
    "            count = 0\n",
    "            for df in data:\n",
    "                self.data_dict[count] = df.copy()\n",
    "                count += 1\n",
    "            del data\n",
    "        else: raise Exception(\"No data passed or data passed was not in list form. Need at least dataframe in a list.\")\n",
    "        \n",
    "        if (type(models) == list) & ( len(models) > 0 ): self.models = models\n",
    "        else: raise Exception(\"No model passed or model(s) passed was not in list form. Need at least one model in a list.\")\n",
    "            \n",
    "        self.tgt = tgt # array of ground truths we are trying to predict\n",
    "                \n",
    "        for i in range(pop_sz):\n",
    "            self.population.append( DNA( list(self.data_dict.keys()), self.preproc_algos, self.models, verbose=self.verbose ) )\n",
    "\n",
    "            \n",
    "    def calc_fitness(self):\n",
    "        '''\n",
    "        Calculates fitness for every member of the population, exponentiates the fitness and calculates population sum\n",
    "        '''\n",
    "        if self.debug: print(\"start of calc_fitness\")\n",
    "        self.fitness_sum = 0\n",
    "    \n",
    "        # For initial population, calculate fitness for every member before generating new members\n",
    "        if self.generations == 0:\n",
    "            self.eval_idxs = [i for i in range(len(self.population))]\n",
    "            for i in self.eval_idxs:\n",
    "                self.population[i].calc_fitness(self.data_dict, self.tgt)\n",
    "                self.population[i].fitness = self.population[i].fitness**self.fit_exp\n",
    "                self.fitness_sum += self.population[i].fitness\n",
    "                \n",
    "        # For all following generations, evaluate only self.eval_perc % of members\n",
    "        else:\n",
    "            if self.eval_perc == 1: self.eval_idxs = [i for i in range(len(self.population))]\n",
    "                \n",
    "            # If not evaluating all mems of pop, randomly select eval_perc * len(pop) mems to eval\n",
    "            else:\n",
    "                self.eval_idxs = []\n",
    "                while len(self.eval_idxs) < self.eval_perc * len(self.population):\n",
    "                    self.eval_idxs.append(np.random.randint(0, len(self.population)))\n",
    "                    self.eval_idxs = list(set(self.eval_idxs))\n",
    "                    \n",
    "            for i in self.eval_idxs:\n",
    "                self.population[i].calc_fitness(self.tgt)\n",
    "                self.population[i].fitness = self.population[i].fitness**self.fit_exp\n",
    "                self.fitness_sum += self.population[i].fitness\n",
    "\n",
    "            \n",
    "    def gen_mating_pool(self):\n",
    "        '''\n",
    "        Generates mating pool as sorted list of tuples (pop_idx, exponentiated_fitness) w/ highest scoring mems first\n",
    "        '''\n",
    "        if self.debug: print(\"start of gen_mating_pool\")\n",
    "        self.mating_pool = []\n",
    "    \n",
    "        for i in range( len(self.eval_idxs) ): \n",
    "    \n",
    "            # Appending (idx, normalized fitness) for each idx in eval_idxs\n",
    "            self.mating_pool.append( (self.eval_idxs[i], self.population[self.eval_idxs[i]].fitness / max(self.fitness_sum, 1e-4) ) )\n",
    "    \n",
    "        # Sorting by fitness score in descending order\n",
    "        self.mating_pool.sort(reverse=True, key = lambda x : x[1])\n",
    "        \n",
    "    \n",
    "    def pick_mem_from_mating_pool(self):\n",
    "        '''\n",
    "        Selects a member (mem) from the mating pool to participate in crossover.\n",
    "\n",
    "        Steps for selection:\n",
    "            1). Draw random number b/w 0-1 (val)\n",
    "            2). Subtract normalized fitness of 1st mem of mating pool (highest fitness) from val\n",
    "            3). If val is now negative, mem of pop corresponding to first mem of mating pool is selected for crossover.\n",
    "            4). If val is still positive, move to 2nd mem of mating pool and repeat until val is negative\n",
    "        '''\n",
    "        if self.debug: print(\"Start of pick_mem_from_mating_pool\")\n",
    "        val = np.random.random()\n",
    "        \n",
    "        if self.verbose: print(f\"val: {val}\")\n",
    "        if self.verbose: print(f\"mating pool: {self.mating_pool}\")\n",
    "            \n",
    "        for i in range( len(self.mating_pool) ):\n",
    "            val -= self.mating_pool[i][1]\n",
    "            if val < 0:\n",
    "                break\n",
    "        if self.verbose: print(f\"idx of mating pool: {self.mating_pool[i][0]}\")\n",
    "        return self.mating_pool[i][0]\n",
    "    \n",
    "    def pick_mem_from_population(self):\n",
    "        '''\n",
    "        Randomly selects a member (mem) from the population to participate in crossover.\n",
    "        '''            \n",
    "        pop_idx = np.random.randint(0, len(self.population))\n",
    "        return pop_idx\n",
    "    \n",
    "    \n",
    "    def gen_new_pop(self):\n",
    "        '''\n",
    "        Generates new members (mems) of population by probabilistically mating existing mems in the mating pool.\n",
    "        Mems of the mating pool w/ higher fitness are more likely to be selected for mating.\n",
    "        '''\n",
    "        if self.debug: print(\"Start of gen_new_pop\")\n",
    "        children = []\n",
    "        \n",
    "        ### Breeding children ###\n",
    "        # For every member we have evaluated, we need to breed a replacement\n",
    "        num_children = int( len(self.eval_idxs) * (1 - self.mating_pool_retain_perc) )\n",
    "        print(f\"Generating {num_children} children\")\n",
    "        for i in range( num_children ): \n",
    "                \n",
    "            # Selecting members to be bred\n",
    "            idx1 = self.pick_mem_from_mating_pool()\n",
    "            if self.eval_perc == 1: idx2 = self.pick_mem_from_mating_pool()\n",
    "            else: idx2 = self.pick_mem_from_mating_pool()\n",
    "            \n",
    "            #THIS WAS NEW --> would want with low mutation rate\n",
    "            # Sampling a random (top 10 fitness) member if idx1 == idx2, w/ 50% probability\n",
    "            if (idx1 == idx2) & (np.random.random() > 0.5): \n",
    "                rand_hi_idx = np.random.randint( min(10, len(self.mating_pool) ) )\n",
    "                idx2 = self.mating_pool[rand_hi_idx][0]\n",
    "                if self.verbose: print(\"idx1 == idx2 dealt with\")\n",
    "            \n",
    "            partnerA = self.population[idx1]\n",
    "            partnerB = self.population[idx2]\n",
    "            \n",
    "            if self.verbose: print(f\"PartnerA: {partnerA.get_phrase()}\")\n",
    "            if self.verbose: print(f\"PartnerB: {partnerB.get_phrase()}\")\n",
    "    \n",
    "            child = partnerA.crossover(partnerB, midpt_bool=self.midpt_bool)\n",
    "            child.mutate(self.mut_rate)\n",
    "            if self.verbose: print(f\"Child: {child.get_phrase()}\")\n",
    "            children.append(child)\n",
    "\n",
    "        ### Updating population ###\n",
    "        if self.replace_bool:    \n",
    "            if self.eval_perc == 1:\n",
    "                for i in range(len(children)):\n",
    "                    replace_idx = self.mating_pool[len(self.mating_pool) - i - 1][0]\n",
    "                    self.population[replace_idx] = children[i] # Overwrites self.population[replace_idx].fitness w/ 0\n",
    "            else: # Can use mating pool for replacements if it is not too small\n",
    "                for i in range(len(children)):\n",
    "#                     replace_idx = self.eval_idxs[i]\n",
    "                    replace_idx = self.mating_pool[len(self.mating_pool) - i - 1][0]\n",
    "                    self.population[replace_idx] = children[i] # Overwrites self.population[replace_idx].fitness w/ 0\n",
    "        else:\n",
    "            self.population.extend(children)\n",
    "\n",
    "        self.generations += 1\n",
    "\n",
    "    def get_best(self):\n",
    "        return self.best\n",
    "\n",
    "    def evaluate(self):\n",
    "        '''\n",
    "        Computes the current \"most fit\" member of the population and whether the perfect score has been achieved.\n",
    "        '''\n",
    "        world_record = 0\n",
    "        idx = 0\n",
    "        for i in range(len(self.population)): \n",
    "            if self.population[i].fitness > world_record:\n",
    "                idx = i\n",
    "                world_record = self.population[i].fitness\n",
    "                \n",
    "        print(f\"World Record: {world_record**(1/self.fit_exp)}\")\n",
    "\n",
    "        self.best = self.population[idx].get_phrase()\n",
    "        if world_record**(1/self.fit_exp) == self.perfect_score:\n",
    "            self.finished = True\n",
    "            \n",
    "        print(f\"Best: {self.get_best()}\")\n",
    "        print(f\"Average: {self.get_average_fitness()}\")\n",
    "\n",
    "        # If we found the target phrase, stop\n",
    "        if self.is_finished():\n",
    "            print(\"We did it :)\")\n",
    "            print(f\"Result: {self.get_best()}\")\n",
    "            print(f\"Num gens: {self.get_generations()}\")\n",
    "\n",
    "            \n",
    "    def get_new_char(self):\n",
    "        all_possible_chars = string.printable[:-10] + \" \"\n",
    "        idx = np.random.randint(len(all_possible_chars))\n",
    "        return all_possible_chars[idx]\n",
    "\n",
    "    def is_finished(self):\n",
    "        return self.finished\n",
    "\n",
    "    def get_generations(self):\n",
    "        return self.generations\n",
    "\n",
    "    def get_average_fitness(self):\n",
    "        total = 0\n",
    "        for i in range( len( self.population ) ):\n",
    "            total += self.population[i].fitness**(1/self.fit_exp)\n",
    "        return total / len(self.population)\n",
    "    \n",
    "    \n",
    "    def evolve(self):\n",
    "    \n",
    "        # Calculate fitness for each mem of pop, take fitness**fit_exp and calc fitness sum\n",
    "        self.calc_fitness()\n",
    "        \n",
    "        # Compute most fit mem of pop and determine if finished\n",
    "        self.evaluate()\n",
    "\n",
    "        # Generate mating pool array by sorting normalized fitness values\n",
    "        self.gen_mating_pool()\n",
    "\n",
    "        # Generate new population mems by crossover b/w existing mems of mating pool\n",
    "        # Either replace existing mems or add new mems to pop\n",
    "        self.gen_new_pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = diabetes.data\n",
    "diabetes_y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dna_data)\n",
    "import dna_data\n",
    "from dna_data import DNA # To get this to work, needed to put 'if name == main' at bottom of dna.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [0, 1]\n",
      "self.genes['data']: [0, 1]\n",
      "data: [0, 1]\n",
      "self.genes['data']: [0, 1]\n",
      "data: [0, 1]\n",
      "self.genes['data']: [0, 1]\n",
      "data: [0, 1]\n",
      "self.genes['data']: [0, 1]\n",
      "data: [0, 1]\n",
      "self.genes['data']: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "data = [diabetes_X[:, : int(diabetes_X.shape[1] / 2)], diabetes_X[:, int(diabetes_X.shape[1] / 2) : ]]\n",
    "preproc_algos = []\n",
    "models = ['rf', 'lr']\n",
    "tgt = diabetes_y\n",
    "pop_sz = 5\n",
    "eval_perc = 50\n",
    "mating_pool_retain_perc = 10\n",
    "mut_rate = 0.05\n",
    "fit_exp = 2\n",
    "pop = Population(data, preproc_algos, models, tgt, mut_rate, pop_sz, fit_exp, eval_perc, mating_pool_retain_perc, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing speed of convergence w/ gene selection based on fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing randomized search\n",
      "Best score: 0.462\n",
      "Best parameters set:\n",
      "\tmax_depth: 6\n",
      "\tmax_features: 6\n",
      "\tmin_samples_leaf: 20\n",
      "\tn_estimators: 23\n",
      "\n",
      "R2 for test_preds: 0.3881500584029627\n",
      "\n",
      " test_preds head: [130.93209796 221.0937203  112.84936298  95.99076261 252.59783986]\n",
      "Linear regression\n",
      "\n",
      "R2 for test_preds: 0.4399387660024645\n",
      "\n",
      " test_preds head: [154.1235067  204.81721599 124.92988001 106.09339576 258.53035681]\n",
      "\n",
      "pred_array.shape: (2, 89)\n",
      "\n",
      "pred_array head: [[130.93209796 154.1235067 ]\n",
      " [221.0937203  204.81721599]\n",
      " [112.84936298 124.92988001]\n",
      " [ 95.99076261 106.09339576]\n",
      " [252.59783986 258.53035681]]\n",
      "pred_array.shape post-processing: (89, 2)\n",
      "\n",
      "y_te: [ 73. 233.  97. 111. 277. 341.  64.  68.  65. 178. 142.  77. 244. 115.\n",
      " 258.  87. 220.  86.  74. 132. 136. 220.  91. 235. 148. 317. 131.  84.\n",
      "  65. 217. 306.  79. 158.  54. 123. 174. 237. 212. 179. 281. 187. 200.\n",
      "  68. 163. 141. 202. 178. 242.  47. 131. 243. 142. 200.  89. 232.  55.\n",
      " 253. 128. 104. 184. 110. 198.  81. 195. 150.  63. 151. 233. 178.  84.\n",
      " 237. 109. 131. 252. 200. 160. 200.  51. 111.  77. 201.  88.  78. 243.\n",
      " 268.  55. 270. 288.  91.]\n",
      "ens_preds.shape: (62, 2)\n",
      "eval_preds.shape: (27, 2)\n",
      "ens_labels.shape: (62,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score from simple weighting: 0.33074356905759605\n",
      "\n",
      "final_wt: 0.3\n",
      "\n",
      "Performing grid search\n",
      "Best score: 0.196\n",
      "\talpha: 1\n",
      "\tl1_ratio: 1\n",
      "\n",
      "el_net coefficients: [0.         0.78140295]\n",
      "\n",
      "Score on el_net eval: 0.2718005687256859\n",
      "\n",
      "Score on training/ensemble samples: 0.5028700099599277\n",
      "\n",
      "Score on lr.score(eval_preds, eval_labels): 0.24874695582364892\n",
      "\n",
      "Score on averaging eval samples: 0.32807435946558183\n",
      "\n",
      "Score on first col eval_preds: 0.2711206542904435\n",
      "\n",
      "Score on full og_preds first col: 0.3881500584029627\n",
      "\n",
      "Score on avg og_preds: 0.4383331345044924\n",
      "\n",
      "LR coefficients: [-0.14299795  1.04481038]\n",
      "LR intercept: 7.626123539989777\n",
      "ens eval preds shape: (27,)\n",
      "\n",
      "eval_preds[:5, :]: [[182.85051872 179.1698153 ]\n",
      " [168.53007895 167.05306138]\n",
      " [208.10864505 208.26816596]\n",
      " [130.93209796 154.1235067 ]\n",
      " [131.24255286 172.51631204]]\n",
      "\n",
      "ens_eval_preds[:5]: [168.67735734 158.06544058 195.46775592 149.93294189 169.10554149]\n",
      "eval_labels[:5]: [141. 174. 268.  73.  77.]\n",
      "ens_eval_preds.shape: (27,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score: 0.24874695582364892\n",
      "\n",
      "Performing randomized search\n",
      "Best score: 0.468\n",
      "Best parameters set:\n",
      "\tmax_depth: 11\n",
      "\tmax_features: 9\n",
      "\tmin_samples_leaf: 12\n",
      "\tn_estimators: 29\n",
      "\n",
      "R2 for test_preds: 0.3804586371842118\n",
      "\n",
      " test_preds head: [123.64263752 210.74884604 106.31358235  84.05235329 263.00963755]\n",
      "Linear regression\n",
      "\n",
      "R2 for test_preds: 0.4399387660024645\n",
      "\n",
      " test_preds head: [154.1235067  204.81721599 124.92988001 106.09339576 258.53035681]\n",
      "\n",
      "pred_array.shape: (2, 89)\n",
      "\n",
      "pred_array head: [[123.64263752 154.1235067 ]\n",
      " [210.74884604 204.81721599]\n",
      " [106.31358235 124.92988001]\n",
      " [ 84.05235329 106.09339576]\n",
      " [263.00963755 258.53035681]]\n",
      "pred_array.shape post-processing: (89, 2)\n",
      "\n",
      "y_te: [ 73. 233.  97. 111. 277. 341.  64.  68.  65. 178. 142.  77. 244. 115.\n",
      " 258.  87. 220.  86.  74. 132. 136. 220.  91. 235. 148. 317. 131.  84.\n",
      "  65. 217. 306.  79. 158.  54. 123. 174. 237. 212. 179. 281. 187. 200.\n",
      "  68. 163. 141. 202. 178. 242.  47. 131. 243. 142. 200.  89. 232.  55.\n",
      " 253. 128. 104. 184. 110. 198.  81. 195. 150.  63. 151. 233. 178.  84.\n",
      " 237. 109. 131. 252. 200. 160. 200.  51. 111.  77. 201.  88.  78. 243.\n",
      " 268.  55. 270. 288.  91.]\n",
      "ens_preds.shape: (62, 2)\n",
      "eval_preds.shape: (27, 2)\n",
      "ens_labels.shape: (62,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score from simple weighting: 0.345871231110076\n",
      "\n",
      "final_wt: 0.5\n",
      "\n",
      "Performing grid search\n",
      "Best score: 0.196\n",
      "\talpha: 1\n",
      "\tl1_ratio: 1\n",
      "\n",
      "el_net coefficients: [0.         0.78140295]\n",
      "\n",
      "Score on el_net eval: 0.2718005687256859\n",
      "\n",
      "Score on training/ensemble samples: 0.5121251680617898\n",
      "\n",
      "Score on lr.score(eval_preds, eval_labels): 0.18123951566899343\n",
      "\n",
      "Score on averaging eval samples: 0.345871231110076\n",
      "\n",
      "Score on first col eval_preds: 0.3200444750399385\n",
      "\n",
      "Score on full og_preds first col: 0.3804586371842118\n",
      "\n",
      "Score on avg og_preds: 0.43107134192999785\n",
      "\n",
      "LR coefficients: [-0.41582406  1.3225681 ]\n",
      "LR intercept: 5.141729115917229\n",
      "ens eval preds shape: (27,)\n",
      "\n",
      "eval_preds[:5, :]: [[180.63340315 179.1698153 ]\n",
      " [168.47666602 167.05306138]\n",
      " [221.19860128 208.26816596]\n",
      " [123.64263752 154.1235067 ]\n",
      " [128.14275986 172.51631204]]\n",
      "\n",
      "ens_eval_preds[:5]: [166.99429643 156.02412799 188.61086139 157.56697925 180.02145777]\n",
      "eval_labels[:5]: [141. 174. 268.  73.  77.]\n",
      "ens_eval_preds.shape: (27,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score: 0.18123951566899343\n",
      "\n",
      "Performing randomized search\n",
      "Best score: 0.453\n",
      "Best parameters set:\n",
      "\tmax_depth: 6\n",
      "\tmax_features: 8\n",
      "\tmin_samples_leaf: 10\n",
      "\tn_estimators: 14\n",
      "\n",
      "R2 for test_preds: 0.37158440263378334\n",
      "\n",
      " test_preds head: [145.47509135 227.82402534 110.23844913  88.04896145 257.84547733]\n",
      "Linear regression\n",
      "\n",
      "R2 for test_preds: 0.4399387660024645\n",
      "\n",
      " test_preds head: [154.1235067  204.81721599 124.92988001 106.09339576 258.53035681]\n",
      "\n",
      "pred_array.shape: (2, 89)\n",
      "\n",
      "pred_array head: [[145.47509135 154.1235067 ]\n",
      " [227.82402534 204.81721599]\n",
      " [110.23844913 124.92988001]\n",
      " [ 88.04896145 106.09339576]\n",
      " [257.84547733 258.53035681]]\n",
      "pred_array.shape post-processing: (89, 2)\n",
      "\n",
      "y_te: [ 73. 233.  97. 111. 277. 341.  64.  68.  65. 178. 142.  77. 244. 115.\n",
      " 258.  87. 220.  86.  74. 132. 136. 220.  91. 235. 148. 317. 131.  84.\n",
      "  65. 217. 306.  79. 158.  54. 123. 174. 237. 212. 179. 281. 187. 200.\n",
      "  68. 163. 141. 202. 178. 242.  47. 131. 243. 142. 200.  89. 232.  55.\n",
      " 253. 128. 104. 184. 110. 198.  81. 195. 150.  63. 151. 233. 178.  84.\n",
      " 237. 109. 131. 252. 200. 160. 200.  51. 111.  77. 201.  88.  78. 243.\n",
      " 268.  55. 270. 288.  91.]\n",
      "ens_preds.shape: (62, 2)\n",
      "eval_preds.shape: (27, 2)\n",
      "ens_labels.shape: (62,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score from simple weighting: 0.3220285568889316\n",
      "\n",
      "final_wt: 0.3\n",
      "\n",
      "Performing grid search\n",
      "Best score: 0.196\n",
      "\talpha: 1\n",
      "\tl1_ratio: 1\n",
      "\n",
      "el_net coefficients: [0.         0.78140295]\n",
      "\n",
      "Score on el_net eval: 0.2718005687256859\n",
      "\n",
      "Score on training/ensemble samples: 0.508620233669069\n",
      "\n",
      "Score on lr.score(eval_preds, eval_labels): 0.22759358333202828\n",
      "\n",
      "Score on averaging eval samples: 0.31736085551512827\n",
      "\n",
      "Score on first col eval_preds: 0.2687512280428048\n",
      "\n",
      "Score on full og_preds first col: 0.37158440263378334\n",
      "\n",
      "Score on avg og_preds: 0.4254114296747996\n",
      "\n",
      "LR coefficients: [-0.34656676  1.24344184]\n",
      "LR intercept: 7.356597588642046\n",
      "ens eval preds shape: (27,)\n",
      "\n",
      "eval_preds[:5, :]: [[187.74221489 179.1698153 ]\n",
      " [145.46778496 167.05306138]\n",
      " [211.02535549 208.26816596]\n",
      " [145.47509135 154.1235067 ]\n",
      " [123.0980936  172.51631204]]\n",
      "\n",
      "ens_eval_preds[:5]: [165.07863094 164.6630644  193.19157497 148.58338301 179.20889033]\n",
      "eval_labels[:5]: [141. 174. 268.  73.  77.]\n",
      "ens_eval_preds.shape: (27,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score: 0.22759358333202828\n",
      "\n",
      "Performing randomized search\n",
      "Best score: 0.435\n",
      "Best parameters set:\n",
      "\tmax_depth: 10\n",
      "\tmax_features: 3\n",
      "\tmin_samples_leaf: 25\n",
      "\tn_estimators: 22\n",
      "\n",
      "R2 for test_preds: 0.3837313135998569\n",
      "\n",
      " test_preds head: [160.66201458 209.5329576  114.08181794  99.66716581 232.6586521 ]\n",
      "Linear regression\n",
      "\n",
      "R2 for test_preds: 0.4399387660024645\n",
      "\n",
      " test_preds head: [154.1235067  204.81721599 124.92988001 106.09339576 258.53035681]\n",
      "\n",
      "pred_array.shape: (2, 89)\n",
      "\n",
      "pred_array head: [[160.66201458 154.1235067 ]\n",
      " [209.5329576  204.81721599]\n",
      " [114.08181794 124.92988001]\n",
      " [ 99.66716581 106.09339576]\n",
      " [232.6586521  258.53035681]]\n",
      "pred_array.shape post-processing: (89, 2)\n",
      "\n",
      "y_te: [ 73. 233.  97. 111. 277. 341.  64.  68.  65. 178. 142.  77. 244. 115.\n",
      " 258.  87. 220.  86.  74. 132. 136. 220.  91. 235. 148. 317. 131.  84.\n",
      "  65. 217. 306.  79. 158.  54. 123. 174. 237. 212. 179. 281. 187. 200.\n",
      "  68. 163. 141. 202. 178. 242.  47. 131. 243. 142. 200.  89. 232.  55.\n",
      " 253. 128. 104. 184. 110. 198.  81. 195. 150.  63. 151. 233. 178.  84.\n",
      " 237. 109. 131. 252. 200. 160. 200.  51. 111.  77. 201.  88.  78. 243.\n",
      " 268.  55. 270. 288.  91.]\n",
      "ens_preds.shape: (62, 2)\n",
      "eval_preds.shape: (27, 2)\n",
      "ens_labels.shape: (62,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score from simple weighting: 0.3510765508861682\n",
      "\n",
      "final_wt: 0.5\n",
      "\n",
      "Performing grid search\n",
      "Best score: 0.196\n",
      "\talpha: 1\n",
      "\tl1_ratio: 1\n",
      "\n",
      "el_net coefficients: [0.         0.78140295]\n",
      "\n",
      "Score on el_net eval: 0.2718005687256859\n",
      "\n",
      "Score on training/ensemble samples: 0.5100744612832449\n",
      "\n",
      "Score on lr.score(eval_preds, eval_labels): 0.19981545614312787\n",
      "\n",
      "Score on averaging eval samples: 0.3510765508861682\n",
      "\n",
      "Score on first col eval_preds: 0.32503481955346913\n",
      "\n",
      "Score on full og_preds first col: 0.3837313135998569\n",
      "\n",
      "Score on avg og_preds: 0.4376824021463508\n",
      "\n",
      "LR coefficients: [-0.44165842  1.24154523]\n",
      "LR intercept: 22.742919480712573\n",
      "ens eval preds shape: (27,)\n",
      "\n",
      "eval_preds[:5, :]: [[171.83952193 179.1698153 ]\n",
      " [167.98422129 167.05306138]\n",
      " [209.45070484 208.26816596]\n",
      " [160.66201458 154.1235067 ]\n",
      " [136.33198811 172.51631204]]\n",
      "\n",
      "ens_eval_preds[:5]: [169.29597664 155.9552046  188.81159934 143.13649195 176.71755281]\n",
      "eval_labels[:5]: [141. 174. 268.  73.  77.]\n",
      "ens_eval_preds.shape: (27,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score: 0.1998154561431279\n",
      "\n",
      "Performing randomized search\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.467\n",
      "Best parameters set:\n",
      "\tmax_depth: 7\n",
      "\tmax_features: 8\n",
      "\tmin_samples_leaf: 13\n",
      "\tn_estimators: 19\n",
      "\n",
      "R2 for test_preds: 0.3777454388131062\n",
      "\n",
      " test_preds head: [151.12848644 230.19841057 102.32261324  85.87881161 256.64030524]\n",
      "Linear regression\n",
      "\n",
      "R2 for test_preds: 0.4399387660024645\n",
      "\n",
      " test_preds head: [154.1235067  204.81721599 124.92988001 106.09339576 258.53035681]\n",
      "\n",
      "pred_array.shape: (2, 89)\n",
      "\n",
      "pred_array head: [[151.12848644 154.1235067 ]\n",
      " [230.19841057 204.81721599]\n",
      " [102.32261324 124.92988001]\n",
      " [ 85.87881161 106.09339576]\n",
      " [256.64030524 258.53035681]]\n",
      "pred_array.shape post-processing: (89, 2)\n",
      "\n",
      "y_te: [ 73. 233.  97. 111. 277. 341.  64.  68.  65. 178. 142.  77. 244. 115.\n",
      " 258.  87. 220.  86.  74. 132. 136. 220.  91. 235. 148. 317. 131.  84.\n",
      "  65. 217. 306.  79. 158.  54. 123. 174. 237. 212. 179. 281. 187. 200.\n",
      "  68. 163. 141. 202. 178. 242.  47. 131. 243. 142. 200.  89. 232.  55.\n",
      " 253. 128. 104. 184. 110. 198.  81. 195. 150.  63. 151. 233. 178.  84.\n",
      " 237. 109. 131. 252. 200. 160. 200.  51. 111.  77. 201.  88.  78. 243.\n",
      " 268.  55. 270. 288.  91.]\n",
      "ens_preds.shape: (62, 2)\n",
      "eval_preds.shape: (27, 2)\n",
      "ens_labels.shape: (62,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score from simple weighting: 0.3247370387667782\n",
      "\n",
      "final_wt: 0.3\n",
      "\n",
      "Performing grid search\n",
      "Best score: 0.196\n",
      "\talpha: 1\n",
      "\tl1_ratio: 1\n",
      "\n",
      "el_net coefficients: [0.         0.78140295]\n",
      "\n",
      "Score on el_net eval: 0.2718005687256859\n",
      "\n",
      "Score on training/ensemble samples: 0.5050860418896688\n",
      "\n",
      "Score on lr.score(eval_preds, eval_labels): 0.23044440173590885\n",
      "\n",
      "Score on averaging eval samples: 0.3197294404597657\n",
      "\n",
      "Score on first col eval_preds: 0.2627606403398782\n",
      "\n",
      "Score on full og_preds first col: 0.3777454388131062\n",
      "\n",
      "Score on avg og_preds: 0.43178256087738953\n",
      "\n",
      "LR coefficients: [-0.24224635  1.1430984 ]\n",
      "LR intercept: 6.60898479011027\n",
      "ens eval preds shape: (27,)\n",
      "\n",
      "eval_preds[:5, :]: [[183.16412298 179.1698153 ]\n",
      " [166.65346206 167.05306138]\n",
      " [222.47809714 208.26816596]\n",
      " [151.12848644 154.1235067 ]\n",
      " [110.03552437 172.51631204]]\n",
      "\n",
      "ens_eval_preds[:5]: [167.04687376 157.19587907 190.78548512 146.17699448 177.15640079]\n",
      "eval_labels[:5]: [141. 174. 268.  73.  77.]\n",
      "ens_eval_preds.shape: (27,)\n",
      "eval_labels.shape: (27,)\n",
      "\n",
      "Score: 0.23044440173590885\n",
      "World Record: 0.24874695582364892\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DNA' object has no attribute 'get_phrase'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-ed06d0586123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-eebab3bc79a9>\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# Compute most fit mem of pop and determine if finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Generate mating pool array by sorting normalized fitness values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-eebab3bc79a9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"World Record: {world_record**(1/self.fit_exp)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mworld_record\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_exp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperfect_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DNA' object has no attribute 'get_phrase'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(2000):\n",
    "    pop.evolve()\n",
    "    if pop.is_finished():\n",
    "        break\n",
    "print(f\"\\nTime: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.DataFrame(data = {'x':[1,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.DataFrame(data = {'y':[4,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = {'test':test, 'test2':test2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('test', 'test2')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(list(z.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   x\n",
       " 0  1\n",
       " 1  2\n",
       " 2  3,    y\n",
       " 0  4\n",
       " 1  2\n",
       " 2  3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[z[key] for key in z.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  4\n",
       "1  2  2\n",
       "2  3  3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([z[key] for key in z.keys()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  4\n",
       "1  2  2\n",
       "2  3  3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([test,test2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5, 5],\n",
       "       [3, 4, 6, 6]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "np.concatenate((a, b.T, b.T), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([5,6])\n",
    "c = np.array([5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape == c.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
